'''
coding:utf-8
@FileName:assembler
@Time:2024/1/20 7:11 PM
@Author: Xiang Xiao
@Email: btxiaox@gmail.com
@Description:
'''
import re
import string
import sys
import os
# å°†å¤–å±‚ç›®å½•æ·»åŠ åˆ° sys.path
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from config import *
import time
import threading
import logger
from .utils import *
from crawler.fanqie_crawler import fanqie_crawler
from crawler.dub import *
from .video_autocut import *
from moviepy.audio.fx.volumex import volumex
from moviepy.video.tools.subtitles import SubtitlesClip
import pysrt
from PIL import Image
import redis
from functools import wraps
import time
from factory import dao




def retry(max_retries=3, delay=1):
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            attempts = 0
            while attempts < max_retries:
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    logger.assemble_logger.error(f"Exception caught: {e}. Retrying...",exc_info=True)
                    attempts += 1
                    time.sleep(delay)
            raise Exception(f"Max retries ({max_retries}) exceeded.")

        return wrapper

    return decorator


def log_progress(stop_event,taskid):
    """
    è®°å½•è§†é¢‘å¤„ç†è¿›åº¦
    :param stop_event:
    :return:
    """
    while not stop_event.is_set():
        logger.assemble_logger.info("Video processing in progress...")
        message_dict = {'taskid': taskid, 'message': f'è¾“å‡ºè§†é¢‘...'}
        logger.ws_logger.info(json.dumps(message_dict))
        stop_event.wait(15)  # æ¯éš” 15 ç§’è®°å½•ä¸€æ¬¡æ—¥å¿—


def assembler(bookid, bgm_name, alias, publish_time, account, content_type=0, voice_type='female',
              video_type='è¥¿é¤ç¾é£Ÿå°åƒè§†é¢‘', platform='fanqie',
              bitrate='5000k', cover_img='girl1_large',is_summary=True, is_test=False):
    """
    è§†é¢‘æ··å‰ªå‡½æ•°ï¼Œ
    :param bookid:
    :param bgm_name:
    :param alias:
    :param publish_time:
    :param account:
    :param content_type:
    :param voice_type:
    :param video_type:
    :param platform:
    :param bitrate:
    :param cover_img:
    :param is_test:
    :return:
    """
    # è·å–å†…å®¹éŸ³é¢‘
    taskid = str(account) + str(bookid)
    fq_crawler = fanqie_crawler()
    message_dict = { 'taskid': taskid, 'message': f'å¼€å§‹è·å–å†…å®¹å’ŒéŸ³é¢‘...' }
    logger.ws_logger.info(json.dumps(message_dict))
    audio_clip, srt_path, book_name = get_text_voice(fq_crawler, bookid, content_type=content_type,
                                                     voice_type=voice_type, use_cache=True,is_summary=is_summary, is_test=is_test)
    # éŸ³é‡æ ‡å‡†åŒ–
    message_dict = {'taskid': taskid, 'message': f'å¤„ç†éŸ³é¢‘+BGM...'}
    logger.ws_logger.info(json.dumps(message_dict))
    audio_clip = audio_clip.audio_normalize()
    video_len = audio_clip.duration
    logger.assemble_logger.info(f'å¤„ç†BGM,BGMä½¿ç”¨çš„æ˜¯{bgm_name}')
    bgm_clip = AudioFileClip(config.bgm_directory + bgm_name + '/head.MP3').audio_normalize()
    bgm_tail_clip = AudioFileClip(config.bgm_directory + bgm_name + '/tail.MP3').audio_normalize()
    if video_len > bgm_clip.duration:
        tmp_bgm_clip = afx.audio_loop(bgm_tail_clip, duration=(video_len - bgm_clip.duration))
        bgm_clip = concatenate_audioclips([bgm_clip, tmp_bgm_clip])
    else:
        bgm_clip = bgm_clip.subclip(t_start=0, t_end=video_len)
    if config.bgm_volume.get(bgm_name) is not None:
        bgm_volume = config.bgm_volume.get(bgm_name)
    else:
        bgm_volume = config.bgm_volume.get('default')
    bgm_clip = bgm_clip.fx(volumex, bgm_volume)
    logger.assemble_logger.info(f'å¤„ç†éŸ³é¢‘ï¼Œåˆå¹¶BGMå’Œå†…å®¹éŸ³é¢‘')
    overlay_audio_clip = CompositeAudioClip([audio_clip, bgm_clip])
    overlay_audio_clip.fps = 44100
    logger.assemble_logger.info(f'åˆå¹¶è§£å‹è§†é¢‘ç´ æ')
    message_dict = {'taskid': taskid, 'message': f'åˆå¹¶ç´ æ...'}
    logger.ws_logger.info(json.dumps(message_dict))
    video_clip, filelog = combineVideo(tim_len=overlay_audio_clip.duration, frag_dur=None, speed=1,
                                       video_type=video_type,
                                       write=False)
    logger.assemble_logger.info(f'éŸ³è§†é¢‘åˆå¹¶')
    message_dict = {'taskid': taskid, 'message': f'éŸ³è§†é¢‘åˆå¹¶...'}
    logger.ws_logger.info(json.dumps(message_dict))
    video_clip = video_clip.set_audio(overlay_audio_clip)
    # åˆ›å»ºå­—å¹•æ–‡æœ¬å‰ªè¾‘
    logger.assemble_logger.info('å¤„ç†å­—å¹•')
    message_dict = {'taskid': taskid, 'message': f'å¤„ç†å­—å¹•...'}
    logger.ws_logger.info(json.dumps(message_dict))
    video_clip = add_srt_to_video(srt_file=srt_path, video_clip=video_clip, video_type=video_type)
    logger.assemble_logger.info('å¤„ç†æ ‡é¢˜åˆ«å')
    message_dict = {'taskid': taskid, 'message': f'å¤„ç†æ ‡é¢˜åˆ«å...'}
    logger.ws_logger.info(json.dumps(message_dict))
    # label_text = config.label_str.get('fanqie') + '\nã€Š' + alias + 'ã€‹'
    label_text = config.label_str.get(platform) + alias
    final_clip = add_label_to_video(text=label_text, pic_file=config.icon_file.get(platform), video_clip=video_clip,
                                    video_type=video_type)
    if is_test:
        output_folder = config.result_directory + '/' + 'test_' + str(bookid) + '_' + book_name
    else:
        output_folder = config.result_directory + '/' + str(bookid) + '_' + book_name
    c_time = str(time.time()).split('.')[0]
    output_path = os.path.join(output_folder, str(bookid) + '_' + bgm_name + '.mp4')
    # ç¡®ä¿è¾“å‡ºæ–‡ä»¶å¤¹è·¯å¾„å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º
    logger.assemble_logger.info('å¤„ç†ç®€ä»‹æ‘˜è¦')
    message_dict = {'taskid': taskid, 'message': f'å¤„ç†ç®€ä»‹æ‘˜è¦...'}
    logger.ws_logger.info(json.dumps(message_dict))
    with open(output_folder + '/' + book_name + '_original_text.txt', 'r') as file:
        # è¯»å–æ–‡ä»¶å†…å®¹
        description = file.read()
        description = get_text_before_dot(description, count=4)
    logger.assemble_logger.info('å¤„ç†title')
    title_str = config.title_str.get(platform) + 'ã€Š' + alias + 'ã€‹'
    logger.assemble_logger.info('è¾“å‡ºç›®å½•ä¸º : ' + output_path)
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)
    with open(os.path.join(output_folder, c_time + '_' + str(bookid) + '_log.txt'), 'w') as file:
        file.write(filelog)
    fps = final_clip.fps
    # å¯¼å‡ºè§†é¢‘
    stop_event = threading.Event()
    threading.Thread(target=log_progress, args=(stop_event,taskid)).start()
    try:
        message_dict = {'taskid': taskid, 'message': f'è¾“å‡ºè§†é¢‘...'}
        logger.ws_logger.info(json.dumps(message_dict))
        final_clip.write_videofile(output_path, codec='h264_videotoolbox', bitrate=bitrate, fps=fps,
                               preset='slow')
    except Exception as e:
        logger.assemble_logger.error(f'è§†é¢‘å¯¼å‡ºå¤±è´¥ï¼Œé”™è¯¯ä¿¡æ¯ï¼š{e}', exc_info=True)
        raise e
    finally:
        stop_event.set()
    # medium
    logger.assemble_logger.info('è§†é¢‘æ–‡ä»¶å†™å…¥å®Œæˆ')
    logger.assemble_logger.info("å¤„ç†å°é¢")
    get_cover_img(text=f"ã€Š{alias}ã€‹", w_l_ratio=final_clip.size[0] / final_clip.size[1], img=cover_img,
                  output_folder=output_folder)
    # push_to_media(account='account',filepath=output_folder,title=f"ç•ªèŒ„å°è¯´souï¼šã€Š{alias}ã€‹",publish_time= publish_time)
    result = {'book_id': bookid, 'alias': alias, 'book_name': book_name, 'account': account, 'filepath': output_folder,'title': title_str,
                'description': description,
                'publish_time': publish_time, 'content_type': 'short_novel'}
    logger.assemble_logger.info(f'å¤„ç†å®Œæˆï¼Œè¿”å›ç»“æœï¼š{result}')
    return result


def get_text_voice(crawler, bookid, content_type=0, voice_type='female', use_cache=True, is_summary=True, is_test=False):
    """
    é€šè¿‡bookidæ‹¿éŸ³é¢‘+å­—å¹•
    :param bookid:
    :param content_type:
    :param voice_type:
    :param use_cache: false é‡æ–°è¯·æ±‚ï¼Œtrueï¼Œä¸é‡æ–°è¯·æ±‚
    :param is_test: è¿”å›æµ‹è¯•å†…å®¹ï¼Œ100ä¸ªå­—
    :return:
    """
    if content_type == 0:
        # çŸ­ç¯‡
        bookinfo = crawler.get_book_info(bookid)
        if is_test:
            # æµ‹è¯•ç¯å¢ƒçš„æ–‡ä»¶å¤¹
            final_output_folder = config.result_directory + '/' + 'test_' + str(bookid) + '_' + bookinfo[0]
        else:
            final_output_folder = config.result_directory + '/' + str(bookid) + '_' + bookinfo[0]
        if use_cache is True and os.path.exists(final_output_folder + '/' + bookinfo[0] + '.mp3'):
            # å¦‚æœæ–‡ä»¶å­˜åœ¨ï¼Œç›´æ¥è¿”å›å­˜é‡çš„å†…å®¹
            srt_path = final_output_folder + '/' + bookinfo[0] + '.srt'
            audio_clip = AudioFileClip(final_output_folder + '/' + bookinfo[0] + '.mp3')
            return audio_clip, srt_path, bookinfo[0]
        logger.assemble_logger.info(f"è·å–éŸ³é¢‘æ–‡ä»¶ï¼š{bookid}")
        bookinfo = crawler.get_book_info(bookid)
        origin_summary,origin_content = crawler.get_content_from_fanqie_dp(bookid,is_summary)
        logger.assemble_logger.info(f"origin_summary:{origin_summary}")
        logger.assemble_logger.info(f"origin_content:{origin_content[:100]}")
        if origin_summary != '' and origin_summary is not None:
            cleaned_summary = clean_the_text(origin_summary)
        cleaned_text = clean_the_text(origin_content) # å»é™¤ç¬¬ä¸€ç« ã€1,ç­‰å†…å®¹
        if is_test:
            # æµ‹è¯•ç¯å¢ƒä¸­åªä¿ç•™100å­—
            cleaned_text = cleaned_text[:100]

        texts = split_content(cleaned_text, gap=6000, end_with='ã€‚')
        paths = []
        for index, text in enumerate(texts):
            paths.append(dubbing_for_long(long_text=text, result_filename=str(bookinfo[0]) + '_' + str(index),
                                          voice_type=voice_type,
                                          output_dir=config.result_directory + '/' + str(bookid) + '_' + bookinfo[0],
                                          use_cache=use_cache))
        info_str = 'book_id : ' + str(bookinfo[2]) + '\n'
        info_str += 'book_name : ' + bookinfo[0] + '\n'
        info_str += 'abstract : ' + bookinfo[1]
        # è·å–æ‘˜è¦,å’Œæ‹†åˆ†çš„summaryåšæ¯”å¯¹
        if origin_summary != '' and origin_summary is not None:
            abstract = cleaned_summary
        else:
            abstract = bookinfo[0]
        if count_chinese_characters(abstract) < 20:
            # å¦‚æœå½“å‰æ‘˜è¦å°äº20ä¸ªå­—ï¼Œå¾—ä»æ­£æ–‡ä¸­æˆªå–
            abstract = split_content(text, gap=30, end_with='ã€‚')[0]
        if not os.path.exists(final_output_folder):
            os.makedirs(final_output_folder)
        with open(config.audio_directory_short + bookinfo[0] + '_info.txt', 'wb') as file:
            file.write(info_str.encode('UTF-8'))
        with open(os.path.join(final_output_folder, bookinfo[0] + '_info.txt'), 'wb') as file:
            file.write(info_str.encode('UTF-8'))
        with open(os.path.join(final_output_folder, bookinfo[0] + '_text.txt'), 'wb') as file:
            file.write(text.encode('UTF-8'))
        with open(os.path.join(final_output_folder, bookinfo[0] + '_original_text.txt'), 'wb') as file:
            file.write(text.encode('UTF-8'))
        with open(config.audio_directory_short + bookinfo[0] + '_text.txt', 'wb') as file:
            file.write(text.encode('UTF-8'))
        with open(os.path.join(final_output_folder, 'abstract.txt'), 'wb') as file:
            file.write(abstract.encode('UTF-8'))
        audio_clip = None
        for path in paths:
            if audio_clip is None:
                audio_clip = AudioFileClip(path[0])
            else:
                audio_clip = concatenate_audioclips([audio_clip, AudioFileClip(path[0])])
        audio_path = final_output_folder + '/' + bookinfo[0] + '.mp3'
        audio_clip.write_audiofile(audio_path)
        srts = []
        for path in paths:
            srts.append(path[1])
        srt_clip = merge_srt(srts)
        srt_path = final_output_folder + '/' + bookinfo[0] + '.srt'
        srt_clip.save(srt_path)
        return audio_clip, srt_path, bookinfo[0]
    else:
        # é•¿ç¯‡
        pass


@retry()
def add_srt_to_video(srt_file, video_clip, video_type):
    srt_config = config.video_setting.get(video_type).get('srt')
    logger.assemble_logger.info(f'æ·»åŠ å­—å¹•æ–‡ä»¶åˆ°è§†é¢‘ä¸­ï¼Œå­—å¹•æ–‡ä»¶{srt_file}')
    with open(srt_file, "r") as input_f, open('temp_srt.srt', "w") as output_f:
        lines = input_f.readlines()
        for i in range(0, len(lines), 4):
            index = lines[i]
            time = lines[i + 1]
            content = lines[i + 2]
            # å‰”é™¤å­—å¹•å†…å®¹ä¸­çš„æ ‡ç‚¹ç¬¦å·
            content = filter_non_chinese(content)
            # ç©ºä¸²å‰”é™¤
            if content == '':
                continue
            # å†™å›åˆ°æ–°æ–‡ä»¶ä¸­
            output_f.write(index)
            output_f.write(time)
            output_f.write(content + '\n')
            output_f.write("\n")

    def generate_text(txt):
        # txt = filter_non_chinese(txt)
        return TextClip(txt, font=srt_config.get('font'), fontsize=srt_config.get('font_size'),
                        color=srt_config.get('color'), stroke_color=srt_config.get('stroke_color'),
                        stroke_width=srt_config.get('stroke_width'),
                        method='caption', size=srt_config.get('size'))

    # subtitles = SubtitlesClip.load_subtitles('temp_srt.srt')
    # subtitles = subtitles.set_text_generator(generate_text)
    subtitles = SubtitlesClip('temp_srt.srt', generate_text)
    result = CompositeVideoClip([video_clip, subtitles.set_position(srt_config.get('srt_position'), relative=False)])
    # åˆ é™¤temp srtå†…å®¹
    os.remove('temp_srt.srt')
    # è¾“å‡ºç»“æœè§†
    # result.write_videofile("output.mp4",fps=video_clip.fps)
    return result


@retry()
def add_label_to_video(text, pic_file, video_clip, video_type):
    # æ‹¿é…ç½®
    label_config = config.video_setting.get(video_type).get('label')
    text_clip = TextClip(text, font=label_config.get('font'), fontsize=label_config.get('font_size'),
                         color=label_config.get('color'), stroke_color=label_config.get('stroke_color'),
                         stroke_width=label_config.get('stroke_width'), size=label_config.get('size'))
    text_clip = text_clip.set_position(label_config.get('txt_position'))
    text_clip = text_clip.set_duration(video_clip.duration)
    if pic_file:
        pic_img = Image.open(pic_file)
        pic_img = pic_img.resize(size=label_config.get('pic_size'))
        pic_img.save('temp_pic.png')
        pic_clip = ImageClip('temp_pic.png')
        pic_clip = pic_clip.set_duration(video_clip.duration)
        pic_clip = pic_clip.set_position(label_config.get('pic_position'))

    video_with_pic = CompositeVideoClip([video_clip, pic_clip])
    video_with_text = CompositeVideoClip([video_with_pic, text_clip])
    # video_with_text.write_videofile("output.mp4",fps=video_clip.fps)
    return video_with_text


@retry()
def merge_srt(srts):
    """
    åˆå¹¶srt
    :param srts:
    :return:
    """
    end = 0
    for index, srt in enumerate(srts):
        subs = pysrt.open(srt)
        if index == 0:
            temp_subs = subs
            t_end_sub = temp_subs[-1]
            end = t_end_sub.index
            end_time = temp_subs[-1].end
        else:
            for sub in subs:
                sub.index = end + sub.index
                sub.shift(hours=end_time.hours, minutes=end_time.minutes, seconds=end_time.seconds,
                          milliseconds=end_time.milliseconds)
                temp_subs.append(sub)
    return temp_subs


def clean_the_text(text, ) -> string:
    cleaned_text = ''.join([char for char in text if char != '"'])
    cleaned_text = cleaned_text.replace('*','')
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é… "ç¬¬xç« " æ ¼å¼çš„å†…å®¹ï¼Œå¹¶å°†å…¶æ›¿æ¢ä¸ºç©ºå­—ç¬¦ä¸²
    # cleaned_text = re.sub(r'(?<!ç¬¬)ç¬¬(?:[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒ\d]+|[1-9]\d*)ç« ', '', cleaned_text)
    return cleaned_text


def get_cover_img(text, img, output_folder="", w_l_ratio=0.75, font='å­—é­‚åŠ²é“é»‘', ):
    # æ‰“å¼€å›¾åƒæ–‡ä»¶
    img = Image.open(config.cover_img.get(img))
    # è®¡ç®—è£å‰ªçš„åŒºåŸŸ
    left = math.floor(img.size[0] / 2 - math.floor(img.size[0] * w_l_ratio / 2))
    right = math.floor(img.size[0] / 2 + math.floor(img.size[0] * w_l_ratio / 2))
    top = 0
    bottom = img.size[1]
    # è£å‰ªå›¾åƒ
    cropped_image = img.crop((left, top, right, bottom))
    cropped_image.save('tmp_cover.png')
    # åˆ›å»º ImageClip å¯¹è±¡
    img_clip = ImageClip('tmp_cover.png')
    # åˆ›å»ºæ–‡æœ¬å‰ªè¾‘
    text_clip = TextClip(txt=text, font=config.font.get(font), fontsize=70, color='white', stroke_color='black',
                         stroke_width=2)
    # è·å–æ–‡æœ¬å‰ªè¾‘çš„å°ºå¯¸
    text_width, text_height = text_clip.size
    # è®¡ç®—æ–‡æœ¬å‰ªè¾‘çš„ä½ç½®ï¼Œä½¿å…¶å±…ä¸­æ˜¾ç¤º
    text_x = (img_clip.size[0] - text_width) / 2
    text_y = (img_clip.size[1] - text_height) / 2
    # è®¾ç½®æ–‡æœ¬å‰ªè¾‘çš„ä½ç½®
    text_clip = text_clip.set_position((text_x, text_y))
    # å°†æ–‡æœ¬å‰ªè¾‘åˆå¹¶åˆ°èƒŒæ™¯è§†é¢‘å‰ªè¾‘ä¸Š
    final_clip = CompositeVideoClip([img_clip, text_clip])
    # ç”Ÿæˆåˆæˆå›¾åƒ
    final_image_np = final_clip.get_frame(0)  # è·å–ç¬¬ 0 ç§’çš„å›¾åƒå¸§
    final_image_pil = Image.fromarray(final_image_np)
    # ä¿å­˜åˆæˆå›¾åƒ
    final_image_pil.save(output_folder + '/' + "cover.png")


def push_to_media(account, filepath, title, publish_time, img_path=None, type='douyin_short'):
    if img_path is None:
        img_path = filepath + '/' + "cover.png"
    with open(filepath + '/' + 'abstract.txt', 'r') as file:
        # è¯»å–æ–‡ä»¶å†…å®¹
        description = file.read()
    url = 'http://127.0.0.1:23335/douyin/' + account
    form = {
        'filepath': filepath,
        'title': title,
        'type': type,
        'description': description,
        'img_path': img_path,
        'publish_time': publish_time
    }
    response = requests.request(method='POST', url=url, data=form, timeout=1500)
    logger.assemble_logger.infologger.assemble_logger.info(response.text)


def push_to_message_queue(book_name, book_id, content_type, alias, account, filepath, title, description, publish_time,
                          img_path=None, type='douyin_short', platform='fanqie'):
    """

    :param book_name: ä¹¦å
    :param book_id: ä¹¦id
    :param content_type:
    :param alias: åˆ«å
    :param account: æŠ–éŸ³è´¦æˆ·
    :param filepath: æ–‡ä»¶ç›®å½•
    :param title: æŠ–éŸ³æ ‡é¢˜
    :param description: æŠ–éŸ³æè¿°
    :param publish_time:
    :param img_path:
    :param type: å®šä½åˆ°tags
    :param platform:
    :return:
    ä¸€ä¸ªmqçš„æ¶ˆæ¯åŒ…ä½“
    {'book_id': 7348020574980951102, 'alias': 'å¤‡èƒæ—¥è®°', 'book_name': 'ä¸å½“èˆ”ç‹—å', 'account': 47040731565,
     'filepath': '/Volumes/å…¬å…±ç©ºé—´/å°è¯´æ¨æ–‡/äº§å‡ºè§†é¢‘/æˆç‰‡/2024-05-12/7348020574980951102_ä¸å½“èˆ”ç‹—å', 'title': 'ç•ªèŒ„å°è¯´souï¼šã€Šå¤‡èƒæ—¥è®°ã€‹',
     'type': 'douyin_short',
     'description': 'åœ¨ä¸€èµ·çš„ç¬¬å…­å¹´ï¼Œæˆ‘è·Ÿè®¸é’°æäº†åˆ†æ‰‹ã€‚åŸå› æ˜¯æˆ‘åœ¨å¥¹çš„è½¦ä¸Šçœ‹åˆ°äº†çŒ«æ¯›ã€‚è€Œå¥¹ä»æ¥ä¸è®©æˆ‘çš„çŒ«ä¸Šå¥¹çš„è½¦ï¼Œå¥¹è¯´å¥¹æœ‰æ´ç™–ã€‚å¬æˆ‘è¿™ä¹ˆè¯´å¥¹æ— æ‰€è°“çš„è€¸è‚©ï¼š[å°±å› ä¸ºè¿™ä¸ªï¼Ÿ]å› ä¸ºè¿™ä¸ªï¼Œä¹Ÿä¸åªå› ä¸ºæ˜¯è¿™ä¸ª',
     'img_path': '/Volumes/å…¬å…±ç©ºé—´/å°è¯´æ¨æ–‡/äº§å‡ºè§†é¢‘/æˆç‰‡/2024-05-12/7348020574980951102_ä¸å½“èˆ”ç‹—å/cover.png', 'platform': 'fanqie',
     'publish_time': '2024-06-01 11:00', 'content_type': 'short_novel'}
    """
    # è¿æ¥åˆ° Redis æœåŠ¡å™¨
    r = redis.StrictRedis(host=REDIS_CONFIG.get('host'), port=REDIS_CONFIG.get('port'), db=REDIS_CONFIG.get('db'))

    # ç”Ÿæˆå”¯ä¸€çš„uuid
    if img_path is None:
        img_path = filepath + '/' + "cover.png"
    form = {
        'book_id': book_id,
        'alias': alias,
        'book_name': book_name,
        'account': account,
        'filepath': filepath,
        'title': title,
        'type': type,
        'description': description,
        'img_path': img_path,
        'platform': platform,
        'publish_time': publish_time,
        'content_type': content_type
    }
    message_id = r.xadd("task_queue", form)
    logger.assemble_logger.info(f"=======å‘é€æ•°æ®idï¼š{message_id},æ¶ˆæ¯ï¼š {form}")


def push_to_mq_test(msg):
    # è¿æ¥åˆ° Redis æœåŠ¡å™¨
    r = redis.StrictRedis(host=REDIS_CONFIG.get('host'), port=REDIS_CONFIG.get('port'), db=REDIS_CONFIG.get('db'))

    message_id = r.xadd("task_queue", msg)
    logger.assemble_logger.info(f"æµ‹è¯•å‘é€æ•°æ®idï¼š{message_id},æ¶ˆæ¯ï¼š {msg}")


def video_output(account_name, bookid, publish_time, bgm_name=None, is_test=False,is_push=True,is_summary= True):
    # å°è£… æ¶ˆæ¯å­—ç¬¦ä¸²
    account = config.account.get(account_name).get('account_id')
    # å°è£…task dict

    taskid = str(account) + str(bookid)
    message_dict = {'taskid': taskid, 'message': f'ä»»åŠ¡å¼€å§‹å¤„ç†'}
    logger.ws_logger.info(json.dumps(message_dict))
    if dao.check_dumplicate(book_id=bookid, account_name=account_name):
        logger.assemble_logger.info(f'video task is duplicate return False')
        message_dict = {'taskid': taskid, 'message': f'ä»»åŠ¡é‡å¤ï¼Œç»“æŸå¤„ç†'}
        logger.ws_logger.info(json.dumps(message_dict))
        raise Exception(message_dict)
    logger.assemble_logger.info(f'å¼€å§‹å¤„ç†ä»»åŠ¡ï¼šä¹¦ç±idæ˜¯ï¼š{bookid},å‘å¸ƒæ—¶é—´ï¼š{publish_time},BGMï¼š{bgm_name},å‘å¸ƒåˆ°è´¦æˆ·ï¼š{account_name}ä¸Š....')
    task = {
        'taskid': taskid,
        'account_name': account_name,
        'book_id': bookid,
        'publish_time': publish_time
    }
    # æŠŠtaskæ·»åŠ åˆ°åˆ—è¡¨é‡Œï¼Œå¹¶è¿”å›index
    task_idx = dao.tasks.push(task)
    logger.assemble_logger.info(f'Task added to queue, index: {task_idx}')
    try:
        if bgm_name is None:
            # éšæœºåˆ†é…éŸ³ä¹
            bgm_dir = '/Volumes/å…¬å…±ç©ºé—´/å°è¯´æ¨æ–‡/BGMç´ æ/'
            bgms = [f.name for f in os.scandir(bgm_dir) if f.is_dir()]
            bgm_name = random.choice(bgms)
        crawler = fanqie_crawler()
        alias_name, alias_id = crawler.get_alias_id(book_id=bookid)

        voice_type = config.account.get(account_name).get('voice_type')
        cover_img = config.account.get(account_name).get('cover_img')
        video_type = config.account.get(account_name).get('video_type')
        result = assembler(bookid=bookid, bgm_name=bgm_name, voice_type=voice_type, account=account, video_type=video_type,
                          cover_img=cover_img, publish_time=publish_time, alias=alias_name,is_summary = is_summary, is_test=is_test)
        # result = {'book_id': '7366551041162103833', 'alias': 'æ‰“è„¸ç”·é—ºèœœ', 'book_name': 'æ„ŸåŒ–ä¸äº†çš„å¦»å­ï¼Œæˆ‘ä¸è¦äº†', 'account': 30365867345, 'filepath': '/Volumes/å…¬å…±ç©ºé—´/å°è¯´æ¨æ–‡/äº§å‡ºè§†é¢‘/æˆç‰‡/2024-05-26/7366551041162103833_æ„ŸåŒ–ä¸äº†çš„å¦»å­ï¼Œæˆ‘ä¸è¦äº†', 'title': 'ğŸ…å°è¯´sou:ã€Šæ‰“è„¸ç”·é—ºèœœã€‹', 'description': 'æ€é’åº†åŠŸå®´ä¸Šï¼Œè€å©†æŠŠèµåŠ©å•†é€çš„ç”·æ¬¾æƒ…ä¾£è¡¨é€ç»™äº†å‰ç”·å‹ã€‚äºŒäººæ‹¿ç€æƒ…ä¾£è¡¨æ‹äº†å¼ æ¥å»ç…§ã€‚å¤§ä¼™å„¿çœ‹äº†æˆ‘ä¸€çœ¼é”™æ„•çš„é—®å¥¹ï¼šâ€œæ²ˆè€å¸ˆï¼Œä½ äº²é”™äººäº†å§ï¼Ÿâ€â€œæˆéƒ½æ‹å®Œäº†ï¼Œè¿™æ˜¯ä»€ä¹ˆæƒ…å†µ', 'publish_time': '0', 'content_type': 'short_novel'}
        if is_push:
            push_to_message_queue(book_name=result.get('book_name'), book_id=result.get('book_id'),
                                  content_type=result.get('content_type'), alias=result.get('alias'),
                                  account=result.get('account'), filepath=result.get('filepath'), title=result.get('title'),
                                  description=result.get('description'), publish_time=result.get('publish_time'),
                                  img_path=result.get('img_path'),)
            return result
        else:
            logger.assemble_logger.info(f'æµ‹è¯•ç¯å¢ƒï¼Œä¸æ¨é€åˆ°æ¶ˆæ¯é˜Ÿåˆ—')
            return result
    except Exception as e:
        logger.assemble_logger.error(f'è§†é¢‘å¤„ç†å¤±è´¥ï¼Œé”™è¯¯ä¿¡æ¯ï¼š{e}', exc_info=True)
        message_dict = {'taskid': taskid, 'message': f'ä»»åŠ¡å¤„ç†å¤±è´¥ï¼Œé”™è¯¯ä¿¡æ¯ï¼š{e}'}
        logger.ws_logger.info(json.dumps(message_dict))
        raise e
    finally:
        dao.tasks.pop(task_idx)
        logger.assemble_logger.info(f'Task removed from queue, index: {task_idx}')




if __name__ == '__main__':
    pass
    push_to_mq_test({'book_id': 7348020574980951102, 'alias': 'å¤‡èƒæ—¥è®°', 'book_name': 'ä¸å½“èˆ”ç‹—å', 'account': 47040731565,
     'filepath': '/Volumes/å…¬å…±ç©ºé—´/å°è¯´æ¨æ–‡/äº§å‡ºè§†é¢‘/æˆç‰‡/2024-05-12/7348020574980951102_ä¸å½“èˆ”ç‹—å', 'title': 'ç•ªèŒ„å°è¯´souï¼šã€Šå¤‡èƒæ—¥è®°ã€‹',
     'type': 'douyin_short',
     'description': 'åœ¨ä¸€èµ·çš„ç¬¬å…­å¹´ï¼Œæˆ‘è·Ÿè®¸é’°æäº†åˆ†æ‰‹ã€‚åŸå› æ˜¯æˆ‘åœ¨å¥¹çš„è½¦ä¸Šçœ‹åˆ°äº†çŒ«æ¯›ã€‚è€Œå¥¹ä»æ¥ä¸è®©æˆ‘çš„çŒ«ä¸Šå¥¹çš„è½¦ï¼Œå¥¹è¯´å¥¹æœ‰æ´ç™–ã€‚å¬æˆ‘è¿™ä¹ˆè¯´å¥¹æ— æ‰€è°“çš„è€¸è‚©ï¼š[å°±å› ä¸ºè¿™ä¸ªï¼Ÿ]å› ä¸ºè¿™ä¸ªï¼Œä¹Ÿä¸åªå› ä¸ºæ˜¯è¿™ä¸ª',
     'img_path': '/Volumes/å…¬å…±ç©ºé—´/å°è¯´æ¨æ–‡/äº§å‡ºè§†é¢‘/æˆç‰‡/2024-05-12/7348020574980951102_ä¸å½“èˆ”ç‹—å/cover.png', 'platform': 'fanqie',
     'publish_time': '2024-06-01 11:00', 'content_type': 'short_novel'})

    # video_output(account_name='douyin_nan1', bookid=7348020574980951102, bgm_name='ç”¨æƒ…',
    #              publish_time='2024-05-14 11:00')
    # video_output(account_name='douyin_nan1', bookid=7355507776015043646, bgm_name='å‡„ç¾åœ°',
    #              publish_time='2024-05-14 18:00')
    # video_output(account_name='douyin_nan1', bookid=7351733248306711614, bgm_name='å¯Œå£«å±±ä¸‹',
    #              publish_time='2024-05-12 10:00')
    # video_output(account_name='douyin_nan1', bookid=7133640097534053406, bgm_name='æš–ä¸€æ¯èŒ¶',
    #              publish_time='2024-05-12 15:00')
    # video_output(account_name='douyin_nan1', bookid=7282959964250112575, bgm_name='å…°äº­åº',
    #              publish_time='2024-05-13 11:00')
    # video_output(account_name='douyin_nan1', bookid=7223704892630633532, bgm_name='å†¬çœ ',
    #              publish_time='2024-05-13 18:00',is_test=True)

    # video_output(account_name='douyin_nv1', bookid=7299355308596399145,
    #              publish_time='2024-05-13 11:00',)
    # video_output(account_name='douyin_nv1', bookid=7314580388494445604,
    #              publish_time='2024-05-13 18:00',)
    # video_output(account_name='douyin_nv1', bookid=7322348136427424830,
    #              publish_time='2024-05-14 11:00',)

    # video_output(account_name='douyin_nv1', bookid=7301877628695219240,
    #              publish_time='2024-05-14 18:00', bgm_name='æš–ä¸€æ¯èŒ¶')
    # video_output(account_name='douyin_nv1', bookid=7264865084881505314,
    #              publish_time='2024-05-15 11:00')
    # video_output(account_name='douyin_nv1', bookid=7348385435980153406,
    #              publish_time='2024-05-16 12:00')

        # video_output(account_name='douyin_nv1', bookid=7369200831616254526, bgm_name='å¯Œå£«å±±ä¸‹',
        #              publish_time=None)
        # video_output(account_name='douyin_nan1', bookid=7366551041162103833, bgm_name='æˆ‘ç¦»å¼€äº†å—äº¬',
        #             publish_time='0')
    # video_output(account_name='douyin_nan1', bookid=7330837915712359486,bgm_name='èµ¤ä¼¶',
    #           publish_time=None)
    # video_output(account_name='douyin_nan1', bookid=7333102653397814334,bgm_name='å‡„ç¾åœ°',
    #              publish_time='2024-05-25 11:00')
    # video_output(account_name='douyin_nv1', bookid=7133640097534053406,bgm_name='æ‚¬æºº',
    #              publish_time='2024-05-24 11:00')
    # video_output(account_name='douyin_nan1', bookid=7330837915712359486,bgm_name='èµ¤ä¼¶',
    #              publish_time='2024-05-23 11:30')

    # assembler(bookid=7355507776015043646, bgm_name='å‡„ç¾åœ°', voice_type='male', video_type='è›‹ä»”ç´ æ',
    #           alias=crawler.ge, publish_time='2024-05-12 10:00', account=config.account.get('douyin_nan1'),
    #           cover_img='girl1_large')
    # assembler(bookid=7282959964250112575, bgm_name='ç”¨æƒ…', voice_type='male', video_type='è›‹ä»”ç´ æ',
    #           alias='é˜¿æ’æ—¥è®°', publish_time='2024-05-06 19:00',account=config.account.get('douyin_nan1'))
